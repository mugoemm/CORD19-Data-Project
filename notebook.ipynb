{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94ea244a-7855-42bd-a0cd-9b7297b4d982",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KSPC Technician1\\AppData\\Local\\Temp\\ipykernel_11552\\2522531505.py:4: DtypeWarning: Columns (1,4,5,6,13,14,15,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"metadata.csv\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>sha</th>\n",
       "      <th>source_x</th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>pmcid</th>\n",
       "      <th>pubmed_id</th>\n",
       "      <th>license</th>\n",
       "      <th>abstract</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>authors</th>\n",
       "      <th>journal</th>\n",
       "      <th>mag_id</th>\n",
       "      <th>who_covidence_id</th>\n",
       "      <th>arxiv_id</th>\n",
       "      <th>pdf_json_files</th>\n",
       "      <th>pmc_json_files</th>\n",
       "      <th>url</th>\n",
       "      <th>s2_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ug7v899j</td>\n",
       "      <td>d1aafb70c066a2068b02786f8929fd9c900897fb</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Clinical features of culture-proven Mycoplasma...</td>\n",
       "      <td>10.1186/1471-2334-1-6</td>\n",
       "      <td>PMC35282</td>\n",
       "      <td>11472636</td>\n",
       "      <td>no-cc</td>\n",
       "      <td>OBJECTIVE: This retrospective chart review des...</td>\n",
       "      <td>2001-07-04</td>\n",
       "      <td>Madani, Tariq A; Al-Ghamdi, Aisha A</td>\n",
       "      <td>BMC Infect Dis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>document_parses/pdf_json/d1aafb70c066a2068b027...</td>\n",
       "      <td>document_parses/pmc_json/PMC35282.xml.json</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02tnwd4m</td>\n",
       "      <td>6b0567729c2143a66d737eb0a2f63f2dce2e5a7d</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Nitric oxide: a pro-inflammatory mediator in l...</td>\n",
       "      <td>10.1186/rr14</td>\n",
       "      <td>PMC59543</td>\n",
       "      <td>11667967</td>\n",
       "      <td>no-cc</td>\n",
       "      <td>Inflammatory diseases of the respiratory tract...</td>\n",
       "      <td>2000-08-15</td>\n",
       "      <td>Vliet, Albert van der; Eiserich, Jason P; Cros...</td>\n",
       "      <td>Respir Res</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>document_parses/pdf_json/6b0567729c2143a66d737...</td>\n",
       "      <td>document_parses/pmc_json/PMC59543.xml.json</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ejv2xln0</td>\n",
       "      <td>06ced00a5fc04215949aa72528f2eeaae1d58927</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Surfactant protein-D and pulmonary host defense</td>\n",
       "      <td>10.1186/rr19</td>\n",
       "      <td>PMC59549</td>\n",
       "      <td>11667972</td>\n",
       "      <td>no-cc</td>\n",
       "      <td>Surfactant protein-D (SP-D) participates in th...</td>\n",
       "      <td>2000-08-25</td>\n",
       "      <td>Crouch, Erika C</td>\n",
       "      <td>Respir Res</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>document_parses/pdf_json/06ced00a5fc04215949aa...</td>\n",
       "      <td>document_parses/pmc_json/PMC59549.xml.json</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2b73a28n</td>\n",
       "      <td>348055649b6b8cf2b9a376498df9bf41f7123605</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Role of endothelin-1 in lung disease</td>\n",
       "      <td>10.1186/rr44</td>\n",
       "      <td>PMC59574</td>\n",
       "      <td>11686871</td>\n",
       "      <td>no-cc</td>\n",
       "      <td>Endothelin-1 (ET-1) is a 21 amino acid peptide...</td>\n",
       "      <td>2001-02-22</td>\n",
       "      <td>Fagan, Karen A; McMurtry, Ivan F; Rodman, David M</td>\n",
       "      <td>Respir Res</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>document_parses/pdf_json/348055649b6b8cf2b9a37...</td>\n",
       "      <td>document_parses/pmc_json/PMC59574.xml.json</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9785vg6d</td>\n",
       "      <td>5f48792a5fa08bed9f56016f4981ae2ca6031b32</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Gene expression in epithelial cells in respons...</td>\n",
       "      <td>10.1186/rr61</td>\n",
       "      <td>PMC59580</td>\n",
       "      <td>11686888</td>\n",
       "      <td>no-cc</td>\n",
       "      <td>Respiratory syncytial virus (RSV) and pneumoni...</td>\n",
       "      <td>2001-05-11</td>\n",
       "      <td>Domachowske, Joseph B; Bonville, Cynthia A; Ro...</td>\n",
       "      <td>Respir Res</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>document_parses/pdf_json/5f48792a5fa08bed9f560...</td>\n",
       "      <td>document_parses/pmc_json/PMC59580.xml.json</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cord_uid                                       sha source_x  \\\n",
       "0  ug7v899j  d1aafb70c066a2068b02786f8929fd9c900897fb      PMC   \n",
       "1  02tnwd4m  6b0567729c2143a66d737eb0a2f63f2dce2e5a7d      PMC   \n",
       "2  ejv2xln0  06ced00a5fc04215949aa72528f2eeaae1d58927      PMC   \n",
       "3  2b73a28n  348055649b6b8cf2b9a376498df9bf41f7123605      PMC   \n",
       "4  9785vg6d  5f48792a5fa08bed9f56016f4981ae2ca6031b32      PMC   \n",
       "\n",
       "                                               title                    doi  \\\n",
       "0  Clinical features of culture-proven Mycoplasma...  10.1186/1471-2334-1-6   \n",
       "1  Nitric oxide: a pro-inflammatory mediator in l...           10.1186/rr14   \n",
       "2    Surfactant protein-D and pulmonary host defense           10.1186/rr19   \n",
       "3               Role of endothelin-1 in lung disease           10.1186/rr44   \n",
       "4  Gene expression in epithelial cells in respons...           10.1186/rr61   \n",
       "\n",
       "      pmcid pubmed_id license  \\\n",
       "0  PMC35282  11472636   no-cc   \n",
       "1  PMC59543  11667967   no-cc   \n",
       "2  PMC59549  11667972   no-cc   \n",
       "3  PMC59574  11686871   no-cc   \n",
       "4  PMC59580  11686888   no-cc   \n",
       "\n",
       "                                            abstract publish_time  \\\n",
       "0  OBJECTIVE: This retrospective chart review des...   2001-07-04   \n",
       "1  Inflammatory diseases of the respiratory tract...   2000-08-15   \n",
       "2  Surfactant protein-D (SP-D) participates in th...   2000-08-25   \n",
       "3  Endothelin-1 (ET-1) is a 21 amino acid peptide...   2001-02-22   \n",
       "4  Respiratory syncytial virus (RSV) and pneumoni...   2001-05-11   \n",
       "\n",
       "                                             authors         journal  mag_id  \\\n",
       "0                Madani, Tariq A; Al-Ghamdi, Aisha A  BMC Infect Dis     NaN   \n",
       "1  Vliet, Albert van der; Eiserich, Jason P; Cros...      Respir Res     NaN   \n",
       "2                                    Crouch, Erika C      Respir Res     NaN   \n",
       "3  Fagan, Karen A; McMurtry, Ivan F; Rodman, David M      Respir Res     NaN   \n",
       "4  Domachowske, Joseph B; Bonville, Cynthia A; Ro...      Respir Res     NaN   \n",
       "\n",
       "  who_covidence_id arxiv_id  \\\n",
       "0              NaN      NaN   \n",
       "1              NaN      NaN   \n",
       "2              NaN      NaN   \n",
       "3              NaN      NaN   \n",
       "4              NaN      NaN   \n",
       "\n",
       "                                      pdf_json_files  \\\n",
       "0  document_parses/pdf_json/d1aafb70c066a2068b027...   \n",
       "1  document_parses/pdf_json/6b0567729c2143a66d737...   \n",
       "2  document_parses/pdf_json/06ced00a5fc04215949aa...   \n",
       "3  document_parses/pdf_json/348055649b6b8cf2b9a37...   \n",
       "4  document_parses/pdf_json/5f48792a5fa08bed9f560...   \n",
       "\n",
       "                               pmc_json_files  \\\n",
       "0  document_parses/pmc_json/PMC35282.xml.json   \n",
       "1  document_parses/pmc_json/PMC59543.xml.json   \n",
       "2  document_parses/pmc_json/PMC59549.xml.json   \n",
       "3  document_parses/pmc_json/PMC59574.xml.json   \n",
       "4  document_parses/pmc_json/PMC59580.xml.json   \n",
       "\n",
       "                                                 url  s2_id  \n",
       "0  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3...    NaN  \n",
       "1  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5...    NaN  \n",
       "2  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5...    NaN  \n",
       "3  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5...    NaN  \n",
       "4  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5...    NaN  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"metadata.csv\")\n",
    "\n",
    "# Show the first 5 rows\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e94cf28d-cf4f-4993-a4db-8c3c91437d65",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1446225658.py, line 2)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mi think it downloade\u001b[39m\n      ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas matplotlib seaborn streamlit\n",
    "i think it downloade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f45cb47-b1d1-4b00-85aa-882980e50d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "!which python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4efb13b-f10e-40e7-9fcd-307edfd9fc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pandas matplotlib seaborn streamlit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb49b6d-6e31-4adc-a326-47b36bf11c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!\"{sys.executable}\" -m pip install pandas matplotlib seaborn streamlit numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9a99c1-2c2c-460a-bc30-ac3fd030d5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"metadata.csv\")\n",
    "\n",
    "# Show first 5 rows\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce31466-2b5b-4e9e-8eed-06e18638c21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset with explicit encoding\n",
    "df = pd.read_csv(\"metadata.csv\", encoding=\"latin1\")\n",
    "\n",
    "# Show first 5 rows\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd43eb9-c0d9-4359-b473-5a850ae3b73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"metadata.csv\", encoding=\"ISO-8859-1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35695e18-7b61-4d1f-805a-d7d60b460068",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"metadata.csv\", encoding=\"latin1\", on_bad_lines=\"skip\", low_memory=False)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c5ef95-d445-4084-8905-b7f8f676c2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"metadata.csv\",\n",
    "    encoding=\"latin1\",\n",
    "    on_bad_lines=\"skip\",\n",
    "    low_memory=False,\n",
    "    engine=\"python\"   # use python engine instead of C\n",
    ")\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd9ed8a-8212-4e73-b365-c4f5190f0ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"metadata.csv\",\n",
    "    encoding=\"latin1\",\n",
    "    on_bad_lines=\"skip\",\n",
    "    engine=\"python\"   # tolerant parser\n",
    ")\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48133173-bac3-41ae-871f-da9d0bc37391",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read directly from zip file\n",
    "df = pd.read_csv(\"metadata.csv.zip\", compression=\"zip\", on_bad_lines=\"skip\", engine=\"python\")\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f37440-f7bb-400c-b4dc-f833e26a8a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"cleaned_cord19.csv\", low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59be08a0-c500-43b2-9f24-640862e17bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98877e16-88b4-4357-9f23-353d9359df84",
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_per_year = df['year'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18042ef-4e39-425f-ab16-cc8863b1a781",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x=papers_per_year.index, y=papers_per_year.values, color=\"skyblue\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Number of Papers Published per Year\", fontsize=14)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Number of Papers\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e379c5e-a408-4938-8679-25f3c23210cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(df['abstract_word_count'], bins=50, kde=True, color=\"orange\")\n",
    "plt.title(\"Distribution of Abstract Word Counts\", fontsize=14)\n",
    "plt.xlabel(\"Word Count\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f620c02-22db-43cd-a792-9bdfa9c1a4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_journals = df['journal'].value_counts().head(10)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x=top_journals.values, y=top_journals.index, palette=\"viridis\")\n",
    "plt.title(\"Top 10 Journals by Number of Papers\", fontsize=14)\n",
    "plt.xlabel(\"Number of Papers\")\n",
    "plt.ylabel(\"Journal\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727de7f5-286a-4d61-8748-10e71c12111a",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_sources = df['source_x'].value_counts().head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb0c052-f5bb-4690-b00a-98f42d92feda",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x=top_sources.values, y=top_sources.index, palette=\"magma\")\n",
    "plt.title(\"Top 10 Sources of Data\", fontsize=14)\n",
    "plt.xlabel(\"Number of Papers\")\n",
    "plt.ylabel(\"Source\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c3a295-c44f-456d-8da4-335d1f953712",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a451f91f-dd85-4aac-bc5b-dfcb40a0082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts = df['abstract'].dropna().astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702ad15b-5072-4d00-b5d3-a6a277d544c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()  # lowercase\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)  # keep only letters and spaces\n",
    "    return text\n",
    "\n",
    "cleaned_abstracts = abstracts.apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866b1aba-e4c5-4357-b2d2-3f4a183dff05",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = \" \".join(cleaned_abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8bedba-6a45-4bfa-a858-6691486f7c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(STOPWORDS)\n",
    "words = [word for word in all_text.split() if word not in stopwords]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3972421-0061-44c9-91bd-e2db30e7e1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq = Counter(words)\n",
    "common_words = word_freq.most_common(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4dd059-62bb-4d72-87b7-4e608c6fd651",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top 20 most common words in abstracts:\")\n",
    "print(common_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec945621-86b4-4e09-9e80-c3129b8cb67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(width=800, height=400, background_color=\"white\", stopwords=stopwords).generate(all_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f39103f-a636-4b25-9918-b4a7d9984e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"WordCloud of Common Terms in Abstracts\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b96209-cd6d-4f1c-a2f9-c15744cffd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "words, counts = zip(*common_words)\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x=list(counts), y=list(words), palette=\"coolwarm\")\n",
    "plt.title(\"Top 20 Most Common Words in Abstracts\", fontsize=14)\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.ylabel(\"Word\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf36c79-b660-4288-8943-463874370d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07323f5-daa8-4879-b6c3-30e86f53adb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81c14c2-d005-477e-afd6-0a1156ff8c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119dc13f-6116-44c8-94e1-e4b5a6a7c537",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e69baee-ea04-4cfe-b951-8d8522cd5f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f93e3f7-7c4f-4689-aff4-30dd99652aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267c1e41-7f8e-429f-b07c-ea153ca66c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b763ef61-60ce-461e-b64c-105e7fc129a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_stopwords = set(stopwords.words(\"english\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9970dad0-0bd5-4027-844d-76aace85d4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import text \n",
    "sklearn_stopwords = set(text.ENGLISH_STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b680b6-499b-46f9-83fd-892e018eeca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_stopwords = nltk_stopwords.union(sklearn_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957ab882-31e9-417e-ac0a-95fc1eebc3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words=combined_stopwords, max_features=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff8e058-927a-4102-8125-be6c37441df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = vectorizer.fit_transform(df[\"abstract\"].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc551e17-017f-4414-8c91-4a69dce08e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc4a486-af5a-4dc9-b90d-84de30b13527",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c94ea9a-b884-4ef7-bdcb-e77fc7644e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_stopwords = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81abb9c-0343-412b-8afe-323fd218f386",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_stopwords = set(text.ENGLISH_STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c91e2a-fee8-44d4-83b2-2c3b704272c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_stopwords = list(nltk_stopwords.union(sklearn_stopwords))  # convert to list ✅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48eeb67-76f6-40a6-8c97-82542059cc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words=combined_stopwords, max_features=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db409fb-97f5-4011-bdfb-d4fb7b3982bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = vectorizer.fit_transform(df[\"abstract\"].dropna())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf63999-a704-48e7-8271-4901a305efe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of features:\", len(vectorizer.get_feature_names_out()))\n",
    "print(\"Some features:\", vectorizer.get_feature_names_out()[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e305196-2e41-4119-a237-2feee5b994e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926d8290-dcd8-4342-a104-f96136042033",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = \" \".join(df[\"abstract\"].dropna().astype(str).tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de09a0f-2245-406a-a86d-c3149bed5db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(\n",
    "    width=1000,\n",
    "    height=600,\n",
    "    background_color=\"white\",\n",
    "    stopwords=set(combined_stopwords),  # same stopwords used in CountVectorizer\n",
    "    colormap=\"viridis\"\n",
    ").generate(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f4c7ed-6cdb-4856-9495-11a097136e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"WordCloud of Abstracts (Cleaned with Combined Stopwords)\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a27abc-e0c1-40a1-b671-3394dbe19242",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc17341-7fa9-4c39-ae45-aedbfedc02a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = vectorizer.fit_transform(df[\"abstract\"].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d39405-3128-49b6-a705-3f917f90e556",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "lda.fit(dtm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3fcf18-f828-46ab-abea-6b1f38acac76",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "lda_display = pyLDAvis.sklearn.prepare(lda, dtm, vectorizer, mds='tsne')\n",
    "\n",
    "lda_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f3ecab-6332-45c4-855a-5157803843ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyLDAvis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f670ebf-e6ca-45b3-b01f-039814456b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1f5b0a-99ae-43a3-837b-90d7ac359926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b088b9c9-8637-4d23-a95f-fd225e39f409",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "lda.fit(dtm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac149527-aa02-4868-a2c4-829dc19b7b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = vectorizer.get_feature_names_out()\n",
    "n_top_words = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dd42f2-b508-48b3-b431-cc851f660cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "    top_indices = topic.argsort()[-n_top_words:][::-1]\n",
    "    top_words = [words[i] for i in top_indices]\n",
    "    top_scores = topic[top_indices]\n",
    "\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.barh(top_words, top_scores, color=\"skyblue\")\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.title(f\"Topic {topic_idx+1}\")\n",
    "    plt.xlabel(\"Word Importance\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b70419-d241-4c5f-ae0a-06e97f78b7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🚀 Part 6: Reporting & Summary\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "report = \"\"\"\n",
    "# 📊 CORD-19 Dataset Analysis – Final Report\n",
    "\n",
    "## 1. Data Overview\n",
    "- Dataset size: {} rows, {} columns\n",
    "- Key fields explored: title, abstract, publish_time, journal, source_x\n",
    "\n",
    "## 2. Cleaning & Preparation\n",
    "- Extracted `year` from `publish_time`\n",
    "- Added `abstract_word_count`\n",
    "- Saved cleaned dataset as `cleaned_cord19.csv`\n",
    "\n",
    "## 3. Descriptive Statistics\n",
    "- **Papers per Year:** Strong increase after 2020 due to COVID-19.\n",
    "- **Top Journals:** bioRxiv, PLoS One, Sci Rep among most frequent.\n",
    "- **Top Sources:** Medline, PMC, WHO collections.\n",
    "\n",
    "## 4. Text Mining on Abstracts\n",
    "- Preprocessed abstracts (lowercased, stopwords removed).\n",
    "- Word frequency analysis highlighted key terms (e.g., \"covid\", \"patients\", \"virus\").\n",
    "- WordCloud showed major research themes visually.\n",
    "\n",
    "## 5. Topic Modeling (LDA)\n",
    "- Extracted thematic clusters from abstracts.\n",
    "- Topics included:\n",
    "  - Clinical research and patients\n",
    "  - Public health and epidemiology\n",
    "  - Virology and molecular studies\n",
    "  - Vaccination and immunity\n",
    "  - Global impact and policy\n",
    "\n",
    "## 6. Key Insights\n",
    "- **COVID-19 drove a massive publication spike starting 2020.**\n",
    "- **Preprints (bioRxiv, medRxiv) were crucial early sources.**\n",
    "- **Research covered clinical, public health, and biological aspects.**\n",
    "- **WordCloud + LDA confirm diverse but COVID-focused themes.**\n",
    "\n",
    "## ✅ Conclusion\n",
    "The CORD-19 dataset provides an invaluable resource for tracking\n",
    "the scientific response to COVID-19. Our analysis combined data\n",
    "cleaning, exploratory analysis, and text mining to uncover trends\n",
    "and themes in global research output.\n",
    "\"\"\".format(df.shape[0], df.shape[1])\n",
    "\n",
    "display(Markdown(report))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17191330-92eb-421f-bd2b-7b2389d50450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save report as Markdown\n",
    "with open(\"report.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(report)\n",
    "\n",
    "print(\"✅ report.md has been saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b718b96-6e52-42e3-b85d-f961ec6ad993",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pypandoc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c0de082-f6eb-4610-b94f-847bb9205b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypandoc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95fa62be-b8f5-45c3-9c7e-b0e0b28dc015",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'report' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m pypandoc.convert_text(\u001b[43mreport\u001b[49m, \u001b[33m'\u001b[39m\u001b[33mmd\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28mformat\u001b[39m=\u001b[33m'\u001b[39m\u001b[33mmd\u001b[39m\u001b[33m'\u001b[39m, outputfile=\u001b[33m'\u001b[39m\u001b[33mfinal_report.md\u001b[39m\u001b[33m'\u001b[39m, extra_args=[\u001b[33m'\u001b[39m\u001b[33m--standalone\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[31mNameError\u001b[39m: name 'report' is not defined"
     ]
    }
   ],
   "source": [
    "pypandoc.convert_text(report, 'md', format='md', outputfile='final_report.md', extra_args=['--standalone'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adb8111f-3971-48d4-855e-8d76dd4cba25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "# 📊 CORD-19 Dataset Analysis – Final Report\n",
       "\n",
       "## 1. Data Overview\n",
       "- Dataset size: 1056660 rows, 19 columns\n",
       "- Key fields explored: title, abstract, publish_time, journal, source_x\n",
       "\n",
       "## 2. Cleaning & Preparation\n",
       "- Extracted `year` from `publish_time`\n",
       "- Added `abstract_word_count`\n",
       "- Saved cleaned dataset as `cleaned_cord19.csv`\n",
       "\n",
       "## 3. Descriptive Statistics\n",
       "- **Papers per Year:** Strong increase after 2020 due to COVID-19.\n",
       "- **Top Journals:** bioRxiv, PLoS One, Sci Rep among most frequent.\n",
       "- **Top Sources:** Medline, PMC, WHO collections.\n",
       "\n",
       "## 4. Text Mining on Abstracts\n",
       "- Preprocessed abstracts (lowercased, stopwords removed).\n",
       "- Word frequency analysis highlighted key terms (e.g., \"covid\", \"patients\", \"virus\").\n",
       "- WordCloud showed major research themes visually.\n",
       "\n",
       "## 5. Topic Modeling (LDA)\n",
       "- Extracted thematic clusters from abstracts.\n",
       "- Topics included:\n",
       "  - Clinical research and patients\n",
       "  - Public health and epidemiology\n",
       "  - Virology and molecular studies\n",
       "  - Vaccination and immunity\n",
       "  - Global impact and policy\n",
       "\n",
       "## 6. Key Insights\n",
       "- **COVID-19 drove a massive publication spike starting 2020.**\n",
       "- **Preprints (bioRxiv, medRxiv) were crucial early sources.**\n",
       "- **Research covered clinical, public health, and biological aspects.**\n",
       "- **WordCloud + LDA confirm diverse but COVID-focused themes.**\n",
       "\n",
       "## ✅ Conclusion\n",
       "The CORD-19 dataset provides an invaluable resource for tracking\n",
       "the scientific response to COVID-19. Our analysis combined data\n",
       "cleaning, exploratory analysis, and text mining to uncover trends\n",
       "and themes in global research output.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OSError",
     "evalue": "No pandoc was found: either install pandoc and add it\nto your PATH or or call pypandoc.download_pandoc(...) or\ninstall pypandoc wheels with included pandoc.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 55\u001b[39m\n\u001b[32m     52\u001b[39m display(Markdown(report))\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# Export to Markdown and PDF\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[43mpypandoc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmd\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmd\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputfile\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfinal_report.md\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m--standalone\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m pypandoc.convert_text(report, \u001b[33m'\u001b[39m\u001b[33mpdf\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28mformat\u001b[39m=\u001b[33m'\u001b[39m\u001b[33mmd\u001b[39m\u001b[33m'\u001b[39m, outputfile=\u001b[33m'\u001b[39m\u001b[33mfinal_report.pdf\u001b[39m\u001b[33m'\u001b[39m, extra_args=[\u001b[33m'\u001b[39m\u001b[33m--standalone\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     58\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✅ Report saved as final_report.md and final_report.pdf\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pypandoc\\__init__.py:94\u001b[39m, in \u001b[36mconvert_text\u001b[39m\u001b[34m(source, to, format, extra_args, encoding, outputfile, filters, verify_format, sandbox, cworkdir)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Converts given `source` from `format` to `to`.\u001b[39;00m\n\u001b[32m     59\u001b[39m \n\u001b[32m     60\u001b[39m \u001b[33;03m:param str source: Unicode string or bytes (see encoding)\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     91\u001b[39m \u001b[33;03m        path.\u001b[39;00m\n\u001b[32m     92\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     93\u001b[39m source = _as_unicode(source, encoding)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mstring\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m                      \u001b[49m\u001b[43moutputfile\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutputfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mverify_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverify_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msandbox\u001b[49m\u001b[43m=\u001b[49m\u001b[43msandbox\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mcworkdir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcworkdir\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pypandoc\\__init__.py:367\u001b[39m, in \u001b[36m_convert_input\u001b[39m\u001b[34m(source, format, input_type, to, extra_args, outputfile, filters, verify_format, sandbox, cworkdir, sort_files)\u001b[39m\n\u001b[32m    364\u001b[39m _check_log_handler()\n\u001b[32m    366\u001b[39m logger.debug(\u001b[33m\"\u001b[39m\u001b[33mEnsuring pandoc path...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m367\u001b[39m \u001b[43m_ensure_pandoc_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m verify_format:\n\u001b[32m    370\u001b[39m     logger.debug(\u001b[33m\"\u001b[39m\u001b[33mVerifying format...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pypandoc\\__init__.py:802\u001b[39m, in \u001b[36m_ensure_pandoc_path\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    794\u001b[39m logger.info(textwrap.dedent(\u001b[33m\"\"\"\u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[32m    795\u001b[39m \u001b[33m    See http://johnmacfarlane.net/pandoc/installing.html\u001b[39m\n\u001b[32m    796\u001b[39m \u001b[33m    for installation options\u001b[39m\n\u001b[32m    797\u001b[39m \u001b[33m\u001b[39m\u001b[33m\"\"\"\u001b[39m))\n\u001b[32m    798\u001b[39m logger.info(textwrap.dedent(\u001b[33m\"\"\"\u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[32m    799\u001b[39m \u001b[33m    ---------------------------------------------------------------\u001b[39m\n\u001b[32m    800\u001b[39m \n\u001b[32m    801\u001b[39m \u001b[33m\u001b[39m\u001b[33m\"\"\"\u001b[39m))\n\u001b[32m--> \u001b[39m\u001b[32m802\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo pandoc was found: either install pandoc and add it\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    803\u001b[39m               \u001b[33m\"\u001b[39m\u001b[33mto your PATH or or call pypandoc.download_pandoc(...) or\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    804\u001b[39m               \u001b[33m\"\u001b[39m\u001b[33minstall pypandoc wheels with included pandoc.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mOSError\u001b[39m: No pandoc was found: either install pandoc and add it\nto your PATH or or call pypandoc.download_pandoc(...) or\ninstall pypandoc wheels with included pandoc."
     ]
    }
   ],
   "source": [
    "# 🚀 Parts 6 + 8: Reporting, Summary, and Export\n",
    "\n",
    "import pypandoc\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Build report content\n",
    "report = \"\"\"\n",
    "# 📊 CORD-19 Dataset Analysis – Final Report\n",
    "\n",
    "## 1. Data Overview\n",
    "- Dataset size: {} rows, {} columns\n",
    "- Key fields explored: title, abstract, publish_time, journal, source_x\n",
    "\n",
    "## 2. Cleaning & Preparation\n",
    "- Extracted `year` from `publish_time`\n",
    "- Added `abstract_word_count`\n",
    "- Saved cleaned dataset as `cleaned_cord19.csv`\n",
    "\n",
    "## 3. Descriptive Statistics\n",
    "- **Papers per Year:** Strong increase after 2020 due to COVID-19.\n",
    "- **Top Journals:** bioRxiv, PLoS One, Sci Rep among most frequent.\n",
    "- **Top Sources:** Medline, PMC, WHO collections.\n",
    "\n",
    "## 4. Text Mining on Abstracts\n",
    "- Preprocessed abstracts (lowercased, stopwords removed).\n",
    "- Word frequency analysis highlighted key terms (e.g., \"covid\", \"patients\", \"virus\").\n",
    "- WordCloud showed major research themes visually.\n",
    "\n",
    "## 5. Topic Modeling (LDA)\n",
    "- Extracted thematic clusters from abstracts.\n",
    "- Topics included:\n",
    "  - Clinical research and patients\n",
    "  - Public health and epidemiology\n",
    "  - Virology and molecular studies\n",
    "  - Vaccination and immunity\n",
    "  - Global impact and policy\n",
    "\n",
    "## 6. Key Insights\n",
    "- **COVID-19 drove a massive publication spike starting 2020.**\n",
    "- **Preprints (bioRxiv, medRxiv) were crucial early sources.**\n",
    "- **Research covered clinical, public health, and biological aspects.**\n",
    "- **WordCloud + LDA confirm diverse but COVID-focused themes.**\n",
    "\n",
    "## ✅ Conclusion\n",
    "The CORD-19 dataset provides an invaluable resource for tracking\n",
    "the scientific response to COVID-19. Our analysis combined data\n",
    "cleaning, exploratory analysis, and text mining to uncover trends\n",
    "and themes in global research output.\n",
    "\"\"\".format(df.shape[0], df.shape[1])\n",
    "\n",
    "# Show report in notebook\n",
    "display(Markdown(report))\n",
    "\n",
    "# Export to Markdown and PDF\n",
    "pypandoc.convert_text(report, 'md', format='md', outputfile='final_report.md', extra_args=['--standalone'])\n",
    "pypandoc.convert_text(report, 'pdf', format='md', outputfile='final_report.pdf', extra_args=['--standalone'])\n",
    "\n",
    "print(\"✅ Report saved as final_report.md and final_report.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "658bddeb-6ab9-41b0-aa20-838501174b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypandoc\n",
    "pypandoc.download_pandoc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5330ae0f-90d4-420b-a35b-f3d305c369ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Pandoc died with exitcode \"47\" during conversion: pdflatex not found. Please select a different --pdf-engine or install pdflatex\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m pypandoc.convert_text(report, \u001b[33m'\u001b[39m\u001b[33mmd\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28mformat\u001b[39m=\u001b[33m'\u001b[39m\u001b[33mmd\u001b[39m\u001b[33m'\u001b[39m, outputfile=\u001b[33m'\u001b[39m\u001b[33mfinal_report.md\u001b[39m\u001b[33m'\u001b[39m, extra_args=[\u001b[33m'\u001b[39m\u001b[33m--standalone\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mpypandoc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpdf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmd\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputfile\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfinal_report.pdf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m--standalone\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pypandoc\\__init__.py:94\u001b[39m, in \u001b[36mconvert_text\u001b[39m\u001b[34m(source, to, format, extra_args, encoding, outputfile, filters, verify_format, sandbox, cworkdir)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Converts given `source` from `format` to `to`.\u001b[39;00m\n\u001b[32m     59\u001b[39m \n\u001b[32m     60\u001b[39m \u001b[33;03m:param str source: Unicode string or bytes (see encoding)\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     91\u001b[39m \u001b[33;03m        path.\u001b[39;00m\n\u001b[32m     92\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     93\u001b[39m source = _as_unicode(source, encoding)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mstring\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m                      \u001b[49m\u001b[43moutputfile\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutputfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mverify_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverify_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msandbox\u001b[49m\u001b[43m=\u001b[49m\u001b[43msandbox\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mcworkdir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcworkdir\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pypandoc\\__init__.py:472\u001b[39m, in \u001b[36m_convert_input\u001b[39m\u001b[34m(source, format, input_type, to, extra_args, outputfile, filters, verify_format, sandbox, cworkdir, sort_files)\u001b[39m\n\u001b[32m    470\u001b[39m \u001b[38;5;66;03m# check that pandoc returned successfully\u001b[39;00m\n\u001b[32m    471\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m p.returncode != \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m472\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    473\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mPandoc died with exitcode \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m during conversion: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m % (p.returncode, stderr)\n\u001b[32m    474\u001b[39m     )\n\u001b[32m    476\u001b[39m \u001b[38;5;66;03m# if there is output on stderr, process it and send to logger\u001b[39;00m\n\u001b[32m    477\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stderr:\n",
      "\u001b[31mRuntimeError\u001b[39m: Pandoc died with exitcode \"47\" during conversion: pdflatex not found. Please select a different --pdf-engine or install pdflatex\r\n"
     ]
    }
   ],
   "source": [
    "pypandoc.convert_text(report, 'md', format='md', outputfile='final_report.md', extra_args=['--standalone'])\n",
    "pypandoc.convert_text(report, 'pdf', format='md', outputfile='final_report.pdf', extra_args=['--standalone'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15b0e77e-4645-4841-9088-5d316ca8e57c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pypandoc.convert_text(report, 'md', format='md', outputfile='final_report.md', extra_args=['--standalone'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fe2576e-9536-4873-ac4a-2c408ef0a060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved as final_report.md and final_report.docx\n"
     ]
    }
   ],
   "source": [
    "pypandoc.convert_text(report, 'docx', format='md', outputfile='final_report.docx', extra_args=['--standalone'])\n",
    "\n",
    "print(\"✅ Saved as final_report.md and final_report.docx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "548ed90e-9490-471a-b0fd-fe31dc1f2f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ PDF export failed (no LaTeX). You can submit .md + .docx instead.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    pypandoc.convert_text(report, 'pdf', format='md', outputfile='final_report.pdf', extra_args=['--standalone'])\n",
    "    print(\"✅ Also saved as final_report.pdf\")\n",
    "except Exception as e:\n",
    "    print(\"⚠️ PDF export failed (no LaTeX). You can submit .md + .docx instead.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8846d7-3daf-4871-bf99-61c24a200513",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
